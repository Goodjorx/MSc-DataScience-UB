{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fd0173b",
      "metadata": {
        "id": "7fd0173b"
      },
      "source": [
        "## Laboratory 4 :POL RIBA MOSOLL (20179725) & JORDI SEGURA PONS (2128790)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f1a88e5",
      "metadata": {
        "id": "9f1a88e5"
      },
      "outputs": [],
      "source": [
        "# Firstly, we import the needed libraries\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib\n",
        "import math as math\n",
        "import matplotlib.pyplot as plt \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46cae42e",
      "metadata": {
        "id": "46cae42e"
      },
      "source": [
        "## 1 - Equality constraints: KKT conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62001ad6",
      "metadata": {
        "id": "62001ad6"
      },
      "source": [
        "### Proposed Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2209e791",
      "metadata": {
        "id": "2209e791"
      },
      "source": [
        "#### 1. Consider $\\alpha^k = 1$ and iteratively update the current point to obtain the next optimal point. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b25b08d",
      "metadata": {
        "id": "7b25b08d"
      },
      "source": [
        "We define all the functions, gradients and hessians we will need during the laboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb9b55d",
      "metadata": {
        "id": "0bb9b55d"
      },
      "outputs": [],
      "source": [
        "def f(x1, x2):\n",
        "\n",
        "    return np.exp(3*x1) + np.exp(-4*x2)\n",
        "\n",
        "def g(x1, x2):\n",
        "\n",
        "    return x1**2 + x2**2 - 1\n",
        "\n",
        "def gradient_f(x1, x2):\n",
        "\n",
        "    return np.matrix([3*np.exp(3*x1), -4*np.exp(-4*x2)])\n",
        "\n",
        "def gradient_g(x1, x2):\n",
        "\n",
        "    return np.matrix([2*x1, 2*x2])\n",
        "\n",
        "def hessian_f(x1, x2):\n",
        "\n",
        "    return np.matrix([[9*np.exp(3*x1),0], [0,16*np.exp(-4*x2)]])\n",
        "    \n",
        "def hessian_g(x1, x2):\n",
        "  \n",
        "    return np.matrix([[2, 0], [0, 2]])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774ed08d",
      "metadata": {
        "id": "774ed08d"
      },
      "source": [
        "Firstly, let's follow the instructions given by the enunciate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rDNQIr7WHzZv",
      "metadata": {
        "id": "rDNQIr7WHzZv"
      },
      "source": [
        "We compute the gradient of functions $f$ and $g$ at the initial point x0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db0b16d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db0b16d7",
        "outputId": "a98a2f83-5ef4-4cdd-86c1-d5f54d50ef4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.14936121 -0.07326256]]\n",
            "[[-2  2]]\n"
          ]
        }
      ],
      "source": [
        "lambda_0 = -1\n",
        "x0 = np.matrix([-1, 1])\n",
        "print(gradient_f(x0[0, 0], x0[0, 1]))\n",
        "print(gradient_g(x0[0, 0], x0[0, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zlc3imfiH7l7",
      "metadata": {
        "id": "zlc3imfiH7l7"
      },
      "source": [
        "We compute the gradient of the Lagrangian at the x0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f25e8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2f25e8c",
        "outputId": "6f956442-ff5f-4eca-d96c-1977ef489fc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[-1.85063879,  1.92673744]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "Gradient_Lag = gradient_f(x0[0, 0], x0[0, 1]) - lambda_0 * gradient_g(x0[0, 0], x0[0, 1])\n",
        "Gradient_Lag"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8UxPO674H_gb",
      "metadata": {
        "id": "8UxPO674H_gb"
      },
      "source": [
        "We compute the hessian of $f$ at x0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79b5bda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d79b5bda",
        "outputId": "5aeedeb4-35cc-49fe-c1e1-61afe9adf759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.44808362, 0.        ],\n",
              "        [0.        , 0.29305022]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "hessian_f(x0[0, 0], x0[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5mGpRiKuIOF8",
      "metadata": {
        "id": "5mGpRiKuIOF8"
      },
      "source": [
        "We compute the hessian of $g$ at x0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d3ff0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98d3ff0a",
        "outputId": "651c8426-e862-4a5f-d067-eda0cfdb1f78",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2, 0],\n",
              "        [0, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "hessian_g(x0[0, 0], x0[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e-QcFU0FISYR",
      "metadata": {
        "id": "e-QcFU0FISYR"
      },
      "source": [
        "We compute the hessian of the Lagrangian at x0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e674c438",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e674c438",
        "outputId": "bf529329-08af-4373-aeee-fc052ea102ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2.44808362, 0.        ],\n",
              "        [0.        , 2.29305022]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "hessian_f(x0[0, 0], x0[0, 1])-lambda_0*hessian_g(x0[0, 0], x0[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ynbTqMe4IfEC",
      "metadata": {
        "id": "ynbTqMe4IfEC"
      },
      "source": [
        "Let's now create the matrices of the linear system to solve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3081f6eb",
      "metadata": {
        "id": "3081f6eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350b0932-353b-4949-bcc8-70dfba8f2347"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 2.44808362,  0.        ,  2.        ],\n",
              "        [ 0.        ,  2.29305022, -2.        ],\n",
              "        [ 2.        , -2.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "M1 = hessian_f(x0[0, 0], x0[0, 1]) - lambda_0*hessian_g(x0[0, 0], x0[0, 1])\n",
        "M2 = - gradient_g(x0[0, 0], x0[0, 1])\n",
        "M_aux = np.concatenate((M1, M2.T), axis=1)\n",
        "Matrix = np.concatenate((M_aux, np.concatenate((M2, [[0]]), axis=1)), axis=0)\n",
        "Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d716704b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d716704b",
        "outputId": "ee29be39-2315-4205-e45d-9beba1076bdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 1.85063879],\n",
              "        [-1.92673744],\n",
              "        [ 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "Residuals = np.concatenate((-Gradient_Lag, [[g(x0[0,0], x0[0,1])]]), axis = 1).T\n",
        "Residuals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7PiaofnNIq-5",
      "metadata": {
        "id": "7PiaofnNIq-5"
      },
      "source": [
        "We solve the linear system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a288c29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a288c29",
        "outputId": "5a2adede-40a1-4907-9709-f0e1c78fb83d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 0.22577436],\n",
              "        [-0.27422564],\n",
              "        [ 0.64896214]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "Solution = np.linalg.solve(Matrix, Residuals)\n",
        "Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LEtS7Ob9JAR1",
      "metadata": {
        "id": "LEtS7Ob9JAR1"
      },
      "source": [
        "We update the point and $\\lambda$ with the results obtained by the solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30d0f41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30d0f41",
        "outputId": "70546671-fc3d-4c26-cd86-5ec36259841b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.77422564  1.22577436]\n",
            " [-1.27422564  0.72577436]]\n",
            "-0.351037859248437\n"
          ]
        }
      ],
      "source": [
        "X = x0 + Solution[0:2,0]\n",
        "Lambda = lambda_0 + Solution[2,0]\n",
        "print(X)\n",
        "print(Lambda)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a25e7b",
      "metadata": {
        "id": "e9a25e7b"
      },
      "source": [
        "The results we obtained in the last exercise are the same as the given in the description of the problem.\n",
        "After 1 iteration of the process, let's build up the function to compute the iterative algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ed1994",
      "metadata": {
        "id": "58ed1994"
      },
      "outputs": [],
      "source": [
        "# Function to compute the iterative algorithm\n",
        "\n",
        "def Optimization(x0 = np.matrix([-1, 1]), lambda0 = -1, Iter = 100):\n",
        "\n",
        "    CountIter = 0\n",
        "\n",
        "    while CountIter < Iter:\n",
        "\n",
        "        Gradient_Lag = gradient_f(x0[0, 0], x0[0, 1]) - lambda0 * gradient_g(x0[0, 0], x0[0, 1])\n",
        "        Hessian_Lag = hessian_f(x0[0, 0], x0[0, 1]) - lambda0 * hessian_g(x0[0, 0], x0[0, 1])\n",
        "        M1 = hessian_f(x0[0, 0], x0[0, 1]) - lambda0 * hessian_g(x0[0, 0], x0[0, 1])\n",
        "        M2 = - gradient_g(x0[0, 0], x0[0, 1])\n",
        "        M_aux = np.concatenate((M1, M2.T), axis=1)\n",
        "        Matrix = np.concatenate((M_aux, np.concatenate((M2, [[0]]), axis=1)), axis=0)\n",
        "        Results = np.concatenate((-Gradient_Lag, [[g(x0[0,0], x0[0,1])]]), axis = 1).T\n",
        "        Solution = np.linalg.solve(Matrix, Results)\n",
        "        x0 = x0 + Solution[0:2,0].T\n",
        "        lambda0 = lambda0 + Solution[2,0]\n",
        "\n",
        "        if np.linalg.norm(Gradient_Lag) < 10**-6:\n",
        "\n",
        "            break\n",
        "\n",
        "        CountIter = CountIter + 1\n",
        "        \n",
        "    return CountIter, x0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46de23c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46de23c1",
        "outputId": "b06edbd5-c175-4f82-fc1c-7496e7bf6e3b",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, matrix([[-0.74833549,  0.66332043]]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "Optimization(x0 = np.matrix([-1, 1]), Iter = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb23f8dd",
      "metadata": {
        "id": "eb23f8dd"
      },
      "source": [
        "As it can be seen in the results above, the function \"Optimization\" prints us the number of iterations computed and the solution. \n",
        "As the solution matches with the suggested on the pdf file using the point (-1, 1) as the initial point, we will conclude that we did it correctly.\n",
        "It reached the optimal solution in 4 iterations, which means the function is very efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b89a31",
      "metadata": {
        "id": "15b89a31"
      },
      "source": [
        "#### 2. Perform some experiments with starting points that are farther away of the optimal solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14517ac6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14517ac6",
        "outputId": "be407665-1be8-4dee-a938-2ccefc14bb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial point (x0): [8, 2]\n",
            "Solution: [[nan nan]]\n",
            "Number of iterations: 100\n",
            "\n",
            "Initial point (x0): [-5, 3]\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "Number of iterations: 6\n",
            "\n",
            "Initial point (x0): [-10, 0]\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "Number of iterations: 7\n",
            "\n",
            "Initial point (x0): [2, 4]\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "Number of iterations: 12\n",
            "\n",
            "Initial point (x0): [-4, -5]\n",
            "Solution: [[ 0.91041323 -0.41370006]]\n",
            "Number of iterations: 18\n"
          ]
        }
      ],
      "source": [
        "points = [[8, 2], [-5, 3], [-10, 0], [2, 4], [-4, -5]]\n",
        "\n",
        "for p in points:\n",
        "  \n",
        "    solution_1 = Optimization(x0 = np.matrix(p), Iter = 100)\n",
        "    print('\\nInitial point (x0): ' + str(p) + '\\nSolution: ' + str(solution_1[1]) + '\\nNumber of iterations: ' + str(solution_1[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "360b2194",
      "metadata": {
        "id": "360b2194"
      },
      "source": [
        "The results above show that when taking points which are close to the solution, the algorithm provides the solution (some times more efficiently than others), but when we try with further points, the function struggles to find the solution, even after 100 iterations (which is the upper treshold we setted up). In one of the points the function gets lost, and ends up a fake solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ca79c6",
      "metadata": {
        "id": "32ca79c6"
      },
      "source": [
        "#### 3. Implement Merit function with $\\rho = 10$ and perform classical gradient descent to find an approximation to the solution we are looking for. Observe if you arrive near to the optimal solution of the problem. (You may have numerical problems with the gradient, normalize it at each iteration)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d56a81",
      "metadata": {
        "id": "72d56a81"
      },
      "source": [
        "We will now implement a code to run the Merit function with $\\rho = 10$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6148fb5",
      "metadata": {
        "id": "e6148fb5"
      },
      "outputs": [],
      "source": [
        "def Merit(x, y):\n",
        "  \n",
        "    return f(x, y) + 10 * g(x, y)**2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_Merit(x, y):\n",
        "  \n",
        "    return np.matrix([gradient_f(x,y)[0,0] + 10*gradient_g(x,y)[0,0], gradient_f(x,y)[0,1] + 10*gradient_g(x,y)[0,1]])"
      ],
      "metadata": {
        "id": "Hv283po2QsyC"
      },
      "id": "Hv283po2QsyC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185aa787",
      "metadata": {
        "id": "185aa787"
      },
      "outputs": [],
      "source": [
        "def gradient_descent_Merit(f, point0x = 0.0, point0y = 0.0, max_iters = 100, treshold = 10**-3):\n",
        "\n",
        "    sol = np.matrix([point0x , point0y])\n",
        "    f_value = f(sol[0,0], sol[0,1])\n",
        "    steps = np.matrix(sol)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "\n",
        "        alpha = 1\n",
        "        sol_aux = sol - alpha * gradient_Merit(sol[0,0], sol[0,1]) / np.linalg.norm(gradient_Merit(sol[0,0], sol[0,1]))\n",
        "        \n",
        "        while(f(sol_aux[0,0], sol_aux[0,1]) > f(sol[0,0], sol[0,1])):\n",
        "\n",
        "            alpha = alpha / 2\n",
        "            sol_aux = sol - alpha * gradient_Merit(sol[0,0], sol[0,1])\n",
        "\n",
        "        if (f(sol[0,0], sol[0,1]) - f(sol_aux[0,0], sol_aux[0,1])) < treshold:\n",
        "            \n",
        "            i -= 1\n",
        "\n",
        "            return sol\n",
        "            \n",
        "        sol = sol_aux.copy()\n",
        "        steps = np.vstack([steps, sol])\n",
        "        f_value = f(sol[0,0], sol[0,1])   \n",
        "    \n",
        "    return sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a5c931",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89a5c931",
        "outputId": "10ab89f9-4011-4636-86ec-46e6bc3517d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[-0.47569926,  0.70337619]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "gradient_descent_Merit(Merit, point0x = 10, point0y = -20, max_iters = 100, treshold = 10**-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c9778ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c9778ab",
        "outputId": "c1491bab-c030-4412-cf3b-9a004f7a25ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[-0.23657222,  0.49839641]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "gradient_descent_Merit(Merit, point0x = 15, point0y = -17, max_iters = 100, treshold = 10**-15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04bbe966",
      "metadata": {
        "id": "04bbe966"
      },
      "source": [
        "The algorithm works correctly for only one of the examples. The solution is not exact but approximately correct, with a small bias to the real solution.\n",
        "To find a good initial point for the \"Optimization\" algorithm, we can use the merit function, while penalizing infeasibility\n",
        "Therefore, using a merit function where we penalize a lot infeasibility is a good method to find a good initial point for the previous algorithm.\n",
        "Let's see how it works to use these points as intial points in the following section. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8fc29ce",
      "metadata": {
        "id": "b8fc29ce"
      },
      "source": [
        "#### 4. Implement first the Merit function to get an approximation of the point we are looking for and after that solution is found, use the Newton-based method to find the optimal solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50808ee7",
      "metadata": {
        "id": "50808ee7"
      },
      "source": [
        "Now, we will mix the Merit function and the Newton method, choosing the points accordingly to the gradient descent method applied on the merit function. Then, we will use the \"Optimization\" algorithm to find the real solution of the optimization problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999adc41",
      "metadata": {
        "id": "999adc41"
      },
      "outputs": [],
      "source": [
        "def Optimization_Upgrade(Merit, x0 = np.matrix([10, -20]), lambda0 = -1, Iter = 100):\n",
        "\n",
        "    x0 = gradient_descent_Merit(Merit, point0x = x0[0,0], point0y = x0[0,1], max_iters = Iter, treshold = 10**-3)\n",
        "    sol = Optimization(x0 = x0, Iter = Iter)\n",
        "    \n",
        "    return x0, sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b1d5b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16b1d5b2",
        "outputId": "daea5e11-530a-4c53-fdf1-275d59cd62dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(matrix([[-0.10770015,  0.49801159]]),\n",
              " (8, matrix([[-0.74833549,  0.66332043]])))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "Optimization_Upgrade(Merit, x0 = np.matrix([35, 55]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dce0c7",
      "metadata": {
        "id": "b6dce0c7"
      },
      "source": [
        "With the initial point (35, 55) the algorithm provides us the correct solution:\n",
        "It also provides us witth the number of iterations, starting points and approximated solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c385be9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c385be9f",
        "outputId": "342735f1-e085-442c-f14e-fbf8eb31d619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial point: [8, 2]\n",
            "Initial point found using gradient descent on Merit function: [[-0.09438169  0.54630267]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [-5, 3]\n",
            "Initial point found using gradient descent on Merit function: [[-0.71157791  0.4291198 ]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [-10, 0]\n",
            "Initial point found using gradient descent on Merit function: [[-0.99118837  0.12044943]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [2, 4]\n",
            "Initial point found using gradient descent on Merit function: [[-0.06639242  0.87001063]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [-4, -5]\n",
            "Initial point found using gradient descent on Merit function: [[-0.68096553  0.11910219]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n"
          ]
        }
      ],
      "source": [
        "# Let's try ow with more values:\n",
        "\n",
        "points2 = [[8, 2], [-5, 3], [-10, 0], [2, 4], [-4, -5]]\n",
        "\n",
        "for p in points2:\n",
        "  \n",
        "    sol = Optimization_Upgrade(Merit, x0 = np.matrix(p), Iter = 100)\n",
        "    print('\\nInitial point: ' + str(p) + '\\nInitial point found using gradient descent on Merit function: ' + str(sol[0]) + '.\\nSolution: ' + str(sol[1][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8582bd7",
      "metadata": {
        "id": "c8582bd7"
      },
      "source": [
        "All the close points found the right solution, because the merit function gives as a good point to start. Therefore, the merit function has improved the performance of our algorithm.\n",
        "\n",
        "We should now try with farther points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6812bc4",
      "metadata": {
        "id": "f6812bc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddf81bc-4c9f-429f-c6cf-c80c9b2025f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial point: [20, -20]\n",
            "Initial point found using gradient descent on Merit function: [[-0.78751718  0.05261548]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [15, 26]\n",
            "Initial point found using gradient descent on Merit function: [[-0.10576867  0.64097129]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [-10, -14]\n",
            "Initial point found using gradient descent on Merit function: [[-0.50789955  0.12188894]].\n",
            "Solution: [[ 0.91041323 -0.41370006]]\n",
            "\n",
            "Initial point: [7.5, 23]\n",
            "Initial point found using gradient descent on Merit function: [[-0.10143924  0.94261223]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n",
            "\n",
            "Initial point: [-33, -50]\n",
            "Initial point found using gradient descent on Merit function: [[-0.9821518   0.12123287]].\n",
            "Solution: [[-0.74833549  0.66332043]]\n"
          ]
        }
      ],
      "source": [
        "# Let's try out with more values, this time a little bit futher from the solution:\n",
        "\n",
        "points3 = [[20, -20], [15, 26], [-10, -14], [7.5, 23], [-33, -50]]\n",
        "\n",
        "for p in points3:\n",
        "  \n",
        "    sol = Optimization_Upgrade(Merit, x0 = np.matrix(p), Iter = 100)\n",
        "    print('\\nInitial point: ' + str(p) + '\\nInitial point found using gradient descent on Merit function: ' + str(sol[0]) + '.\\nSolution: ' + str(sol[1][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a62f10",
      "metadata": {
        "id": "f6a62f10"
      },
      "source": [
        "Again, we prove that this method works even with very far points, with a very small bias compared to the real solution.\n",
        "Therefore, we can say it is a good method to use."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Minimizing the force applied to an object."
      ],
      "metadata": {
        "id": "oYaSqgRGWLXh"
      },
      "id": "oYaSqgRGWLXh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, as it has been stated in class, we will make use of the Hamiltonian in order to find the minimum force we have to apply to an object to move it from position $x_0$ to $x_1$ in $T$ seconds.\n",
        "\n",
        "First of all, we need to declare the function and its physical restrictions, such that:\n",
        "\n",
        "$F=m \\cdot x^{\\prime\\prime} = m \\cdot v^{\\prime} = u$\n",
        "\n",
        "$\\begin{align*}\n",
        "x^\\prime &= v \\\\\n",
        "v' &= \\frac{u}{m}\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "Once here, we need to build our Hamiltonian, which is compressed with the cost function we want to reduce, or minimize,($u$) and the constraints:\n",
        "\n",
        "$H = |u|^2 + \\lambda_1 v + \\lambda_2 \\frac{u}{m}$\n",
        "\n",
        "Now, with the Hamiltonian in our hands, we need to minimize it to find the desired force. Hence:\n",
        "\n",
        "$\\frac{\\partial H}{\\partial u} = 0 \\mapsto 2u + \\lambda_2 \\frac{1}{m} = 0 \\mapsto u = -\\lambda_2 \\frac{1}{2m}$\n",
        "\n",
        "As we are considering these constraints in our whole system, we also need to derivate them:\n",
        "\n",
        "$\\lambda_1^\\prime = -\\frac{\\partial H}{\\partial x} = 0 \\mapsto \\lambda_1 = k$\n",
        "\n",
        "$\\lambda_2^\\prime = -\\frac{\\partial H}{\\partial v} = -\\lambda_1 \\mapsto \\lambda_2 = -kt + c $\n",
        "\n",
        "Then, if we substitute these values in the previous expression of our $u$, we get:\n",
        "$u(t) = -\\lambda_2 \\frac{1}{2m} = \\frac{kt - c}{2m}$\n",
        "\n",
        "Therefore, integrating this function, we are able to find $v(t)$ and $x(t)$:\n",
        "\n",
        "$\n",
        "\\begin{align*}\n",
        "v(t) &= \\int \\frac{u(t)}{m} \\, \\mathrm{d}t = \\frac{1}{2m^2} \\int kt - c \\, \\mathrm{d}t \\\\\n",
        "&= \\frac{1}{2m^2} \\left( \\frac{1}{2} kt^2 - ct \\right) + C\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "$\\begin{align*}\n",
        "x(t) &= \\int \\left( \\frac{1}{2m^2} \\left( \\frac{1}{2} kt^2 - ct \\right) + C \\right) \\, \\mathrm{d}t \\\\\n",
        "&= \\frac{1}{2m^2} \\int \\left( \\frac{1}{2} kt^2 - ct + C \\right) \\, \\mathrm{d}t + \\int C \\, \\mathrm{d}t \\\\\n",
        "&= \\frac{1}{2m^2} \\left( \\frac{1}{6} kt^3 - \\frac{1}{2} ct^2 +Ct \\right) + C'\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "And finally, we can evaluate at the boundaries established in class, which were using $T=1$ and we know the final position is also equal to 1. \n",
        "\n",
        "$\n",
        "\\begin{align*}\n",
        "x(0) &= \\frac{1}{2m^2} \\left( \\frac{1}{6} k(0)^3 - \\frac{1}{2} c(0)^2 \\right) + C' = 0  &\\mapsto C'=0\\\\\n",
        "x(1) &= \\frac{1}{2m^2} \\left( \\frac{1}{6} k(1)^3 - \\frac{1}{2} c(1)^2 + C \\right) + C' = 1 &\\mapsto \\frac{1}{2m^2} \\left( \\frac{k}{6}- \\frac{c}{2} +C \\right ) = 1\\\\\n",
        "v(0) &= \\frac{1}{2m^2} \\left( \\frac{1}{2} k(0)^2 - c(0) \\right) + C = 0 &\\mapsto C = 0\\\\\n",
        "v(1) &= \\frac{1}{2m^2} \\left( \\frac{1}{2} k(1)^2 - c(1) \\right) + C = 0 &\\mapsto \\frac{1}{2m^2} \\left( \\frac{k}{2}- c \\right ) = 0 &\\mapsto c = \\frac{k}{2}\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "$\n",
        "\\begin{align*}\n",
        "\\frac{1}{2m^2} \\left( \\frac{k}{6} - \\frac{k}{4} \\right) - 1 &= 0 \\\\\n",
        "\\frac{1}{2m^2} \\cdot \\frac{-k}{12} - 1 &= 0 \\\\\n",
        "k &= -24m^2\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "So, finallly:\n",
        "\n",
        "$u(t) = \\frac{kt - c}{2m} =\\frac{-24m^2t}{2m} + \\frac{12m^2}{2m} = -12mt + 6m $\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OiGpOFrZWNdb"
      },
      "id": "OiGpOFrZWNdb"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "m = [0.1, 0.5, 1]\n",
        "t = np.arange(0, 1.01, 0.01)\n",
        "\n",
        "for i in range(len(m)):\n",
        "    y = [-12 * m[i] * x + 6 * m[i] for x in t]\n",
        "    plt.plot(t, y, label=f'm={m[i]}')\n",
        "\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dzYyI1Q8coMp",
        "outputId": "64e3424d-c2d2-4988-eb58-cfd3b32f7961"
      },
      "id": "dzYyI1Q8coMp",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows us the different force we need to apply at each second depending on the mass we must move from position $x_0$ to $x_1$ in 1 second!"
      ],
      "metadata": {
        "id": "VsJWwT9ucqiu"
      },
      "id": "VsJWwT9ucqiu"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ur-tLzZtdY_c"
      },
      "id": "ur-tLzZtdY_c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "46cae42e"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}